{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "dd27c087",
      "metadata": {
        "id": "dd27c087"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from datasets import load_dataset\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import cohere\n",
        "import numpy as np\n",
        "import warnings\n",
        "from IPython.display import display\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "API keys:"
      ],
      "metadata": {
        "id": "293MIWyDhO-8"
      },
      "id": "293MIWyDhO-8"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "33e6f5b3",
      "metadata": {
        "id": "33e6f5b3"
      },
      "outputs": [],
      "source": [
        "with open(\"/content/cohere_api_key.txt\") as f:\n",
        "    COHERE_API_KEY = f.read().strip()\n",
        "with open(\"/content/pinecone_api_key.txt\") as f:\n",
        "    PINECONE_API_KEY = f.read().strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Preprocessing & Embedding the data**"
      ],
      "metadata": {
        "id": "9tFpFp_4g_aF"
      },
      "id": "9tFpFp_4g_aF"
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "25de8986",
      "metadata": {
        "id": "25de8986"
      },
      "outputs": [],
      "source": [
        "def load_and_embedd_dataset(\n",
        "        dataset_name: str = 'community-datasets/yahoo_answers_topics',\n",
        "        split: str = 'train',\n",
        "        model: SentenceTransformer = SentenceTransformer('all-MiniLM-L6-v2'),\n",
        "        text_field: str = 'best_answer',\n",
        "        rec_num: int = 400\n",
        ") -> tuple:\n",
        "    \"\"\"\n",
        "    Load a dataset and embedd the text field using a sentence-transformer model\n",
        "    Args:\n",
        "        dataset_name: The name of the dataset to load\n",
        "        split: The split of the dataset to load\n",
        "        model: The model to use for embedding\n",
        "        text_field: The field in the dataset that contains the text\n",
        "        rec_num: The number of records to load and embedd\n",
        "    Returns:\n",
        "        tuple: A tuple containing the dataset and the embeddings\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Loading and embedding the dataset\")\n",
        "\n",
        "    # Load the dataset\n",
        "    dataset = load_dataset(dataset_name, split=split)\n",
        "\n",
        "    # Embed the first `rec_num` rows of the dataset\n",
        "    embeddings = model.encode(dataset[text_field][:rec_num])\n",
        "\n",
        "    print(\"Done!\")\n",
        "    return dataset, embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "9d558650",
      "metadata": {
        "id": "9d558650"
      },
      "outputs": [],
      "source": [
        "EMBEDDING_MODEL = 'all-MiniLM-L6-v2'\n",
        "model = SentenceTransformer(EMBEDDING_MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "3bff82e2",
      "metadata": {
        "id": "3bff82e2",
        "outputId": "9356a533-bba7-4312-bdaa-4ceee112838f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and embedding the dataset\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "DATASET_NAME = 'community-datasets/yahoo_answers_topics'\n",
        "\n",
        "dataset, embeddings = load_and_embedd_dataset(\n",
        "    dataset_name=DATASET_NAME,\n",
        "    rec_num=2000,\n",
        "    model=model,\n",
        "    text_field='best_answer'\n",
        ")\n",
        "shape = embeddings.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8474a04",
      "metadata": {
        "id": "a8474a04"
      },
      "source": [
        "# **Inserting the data into Pinecone VectorDB**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### creating the index"
      ],
      "metadata": {
        "id": "KD8nsD7kpP7V"
      },
      "id": "KD8nsD7kpP7V"
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "de149555",
      "metadata": {
        "id": "de149555"
      },
      "outputs": [],
      "source": [
        "def create_pinecone_index(\n",
        "        index_name: str,\n",
        "        dimension: int,\n",
        "        metric: str = 'cosine',\n",
        "):\n",
        "    \"\"\"\n",
        "    Create a pinecone index if it does not exist\n",
        "    Args:\n",
        "        index_name: The name of the index\n",
        "        dimension: The dimension of the index\n",
        "        metric: The metric to use for the index\n",
        "    Returns:\n",
        "        Pinecone: A pinecone object which can later be used for upserting vectors and connecting to VectorDBs\n",
        "    \"\"\"\n",
        "    print(\"Creating a Pinecone index...\")\n",
        "    pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "    existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
        "    if index_name not in existing_indexes:\n",
        "        pc.create_index(\n",
        "            name=index_name,\n",
        "            dimension=dimension,\n",
        "\n",
        "            metric=metric,\n",
        "            spec=ServerlessSpec(\n",
        "                cloud=\"aws\",\n",
        "                region=\"us-east-1\"\n",
        "            )\n",
        "        )\n",
        "    print(\"Done!\")\n",
        "    return pc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "e6e59ce9",
      "metadata": {
        "id": "e6e59ce9",
        "outputId": "932401f8-5671-48d4-d61d-2e5a0ac62147",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating a Pinecone index...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "INDEX_NAME = 'yahoo-answers'\n",
        "\n",
        "# Create the vector database\n",
        "# We are passing the index_name and the size of our embeddings\n",
        "pc = create_pinecone_index(INDEX_NAME, shape[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99bdf2a1",
      "metadata": {
        "id": "99bdf2a1"
      },
      "source": [
        "inserting data into the index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "f22e0176",
      "metadata": {
        "id": "f22e0176"
      },
      "outputs": [],
      "source": [
        "def upsert_vectors(\n",
        "        index: Pinecone,\n",
        "        embeddings: np.ndarray,\n",
        "        dataset: dict,\n",
        "        text_field: str = 'best_answer',\n",
        "        batch_size: int = 128\n",
        "):\n",
        "    \"\"\"\n",
        "    Upsert vectors to a pinecone index\n",
        "    Args:\n",
        "        index: The pinecone index object\n",
        "        embeddings: The embeddings to upsert\n",
        "        dataset: The dataset containing the metadata\n",
        "        batch_size: The batch size to use for upserting\n",
        "    Returns:\n",
        "        An updated pinecone index\n",
        "    \"\"\"\n",
        "    print(\"Upserting the embeddings to the Pinecone index...\")\n",
        "    shape = embeddings.shape\n",
        "\n",
        "    ids = [str(i) for i in range(shape[0])]\n",
        "    meta = [{text_field: text} for text in dataset[text_field]]\n",
        "\n",
        "    # create list of (id, vector, metadata) tuples to be upserted\n",
        "    to_upsert = list(zip(ids, embeddings, meta))\n",
        "\n",
        "    for i in tqdm(range(0, shape[0], batch_size)):\n",
        "        i_end = min(i + batch_size, shape[0])\n",
        "        index.upsert(vectors=to_upsert[i:i_end])\n",
        "    return index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "ee8f4096",
      "metadata": {
        "id": "ee8f4096",
        "outputId": "e25b8f61-50f5-46d2-f0b6-9aa7f1451032",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upserting the embeddings to the Pinecone index...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:07<00:00,  2.19it/s]\n"
          ]
        }
      ],
      "source": [
        "# Upsert the embeddings to the Pinecone index\n",
        "index = pc.Index(INDEX_NAME)\n",
        "index_upserted = upsert_vectors(index, embeddings, dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "085fe0ef",
      "metadata": {
        "id": "085fe0ef",
        "outputId": "f02cc313-6dcb-40a4-8297-344247d77700",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dimension': 384,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {'': {'vector_count': 2000}},\n",
              " 'total_vector_count': 2000}"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrieving relevant documents and generating answers to given questions using the retrieved documents & an LLM\n"
      ],
      "metadata": {
        "id": "pBlvY0cz08Xy"
      },
      "id": "pBlvY0cz08Xy"
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "id": "bb91e350",
      "metadata": {
        "id": "bb91e350"
      },
      "outputs": [],
      "source": [
        "def augment_prompt(\n",
        "        query: str,\n",
        "        model: SentenceTransformer = SentenceTransformer('all-MiniLM-L6-v2'),\n",
        "        index=None,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Augment the prompt with the top 3 results from the knowledge base\n",
        "    Args:\n",
        "        query: The query to augment\n",
        "        index: The vectorstore object\n",
        "    Returns:\n",
        "        str: The augmented prompt\n",
        "    \"\"\"\n",
        "    results = [float(val) for val in list(model.encode(query))]\n",
        "\n",
        "    # get top 3 results from knowledge base\n",
        "    query_results = index.query(\n",
        "        vector=results,\n",
        "        top_k=10,\n",
        "        include_values=True,\n",
        "        include_metadata=True\n",
        "    )['matches']\n",
        "    text_matches = [match['metadata']['best_answer'] for match in query_results]\n",
        "\n",
        "    # get the text from the results\n",
        "    source_knowledge = \"\\n\\n\".join(text_matches)\n",
        "\n",
        "    # feed into an augmented prompt\n",
        "    augmented_prompt = f\"\"\"Using the contexts below, answer the query.\n",
        "    Contexts:\n",
        "    {source_knowledge}\n",
        "    If the answer is not included in the source knowledge - say that you don't know. please answer shortly.\n",
        "    Query: {query}\"\"\"\n",
        "    return augmented_prompt, source_knowledge"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_simple_answer(query):\n",
        "  co = cohere.Client(api_key=COHERE_API_KEY)\n",
        "  response = co.chat(\n",
        "        model='command-r-plus',\n",
        "        message=query,\n",
        "    )\n",
        "  print(response.text)"
      ],
      "metadata": {
        "id": "ar5M1ufA_DrN"
      },
      "id": "ar5M1ufA_DrN",
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_augmented_answer(query):\n",
        "  augmented_prompt, source_knowledge = augment_prompt(query, model=model, index=index)\n",
        "  co = cohere.Client(api_key=COHERE_API_KEY)\n",
        "  response = co.chat(\n",
        "        model='command-r-plus',\n",
        "        message=augmented_prompt,\n",
        "    )\n",
        "  print(response.text)"
      ],
      "metadata": {
        "id": "R71e3se0_f2e"
      },
      "id": "R71e3se0_f2e",
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Questions:\n",
        "1. What is the name of the first person who trained dogs to help blind people?\n",
        "2.  Where did the band, The Dismemberment Plan, get their name from?\n",
        "3. What year did Virgin Galactic say they would fly tourists to space?"
      ],
      "metadata": {
        "id": "SEJpUqOq1ZhH"
      },
      "id": "SEJpUqOq1ZhH"
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "id": "f59275f9",
      "metadata": {
        "id": "f59275f9",
        "outputId": "a5afac2d-9e4c-4216-b615-7e40c4d07432",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query 1:\n",
            "\n",
            "answer without RAG:\n",
            "The first person to train dogs to assist blind people was a German pastor named Johann Wilhelm Klein. He founded an institution in 1819 that taught crafts and skills to blind people to help them become more independent. As part of this mission, he began training dogs to guide the blind, and in 1835, he successfully paired the first guide dog with a blind person. This pioneering work laid the foundation for the modern guide dog programs that have since transformed the lives of countless individuals with visual impairments.\n",
            "\n",
            "\n",
            "RAG answer:\n",
            "Josef Riesinger\n",
            "--------------------------------------------------\n",
            "query 2:\n",
            "\n",
            "answer without RAG:\n",
            "The band The Dismemberment Plan, formed in Washington, D.C. in 1993, chose their unique and attention-grabbing name through a democratic process. The band members put suggested names into a hat, and \"The Dismemberment Plan\" was the one randomly drawn out. The name stuck, and the band went on to build a successful career with this intriguing moniker.\n",
            "\n",
            "\n",
            "RAG answer:\n",
            "From the movie Groundhog Day.\n",
            "--------------------------------------------------\n",
            "query 3:\n",
            "\n",
            "answer without RAG:\n",
            "2023\n",
            "\n",
            "\n",
            "RAG answer:\n",
            "2008\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "queries = [\"what is the name of the first person who trained dogs to help blind people?\",\n",
        "           \"Where did the band, The Dismemberment Plan, get their name from?\",\n",
        "           \"what year did Virgin Galactic say they would fly tourists to space?\"\n",
        "          ]\n",
        "for i, query in enumerate(queries):\n",
        "  print(f\"query {i+1}:\\n\")\n",
        "  print(\"answer without RAG:\")\n",
        "  generate_simple_answer(query)\n",
        "  print(\"\\n\")\n",
        "  print(\"RAG answer:\")\n",
        "  generate_augmented_answer(query)\n",
        "  print(\"-\"*50)"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}